{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "iafPdtuncbq7"
   },
   "source": [
    "<h1><center>MNIST classification using Keras<center></h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Student : Frank Enrique Facundo Raime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "I4VrCB5La5rD"
   },
   "source": [
    "# Importing Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "OlKZ3Hnas7B4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using tensorflow version 2.1.0\n",
      "Using keras version 2.3.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# Importing the Keras main module forcing tensorflow 1.x backend\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "print(\"Using tensorflow version \" + str(tf.__version__))\n",
    "print(\"Using keras version \" + str(keras.__version__))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "s_QLz9_jbRZq"
   },
   "source": [
    "## Loading and preparing the MNIST dataset\n",
    "\n",
    "Load the MNIST dataset via keras.datasets. Again, turn train and test labels into one-hot encoding, and reshape and normalize data as in the first exercise. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "cellView": "both",
    "colab": {},
    "colab_type": "code",
    "id": "gG83hGyVmijn"
   },
   "outputs": [],
   "source": [
    "#@title\n",
    "# The MNSIT dataset is ready to be imported from Keras into RAM\n",
    "# Warning: you cannot do that for larger databases (e.g., ImageNet)\n",
    "from keras.datasets import mnist\n",
    "# START CODE HERE\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "\n",
    "# END CODE HERE\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "lQbkllF8mnaf"
   },
   "outputs": [],
   "source": [
    "from keras.utils.np_utils import to_categorical\n",
    "# START CODE HERE\n",
    "y_train = keras.utils.to_categorical(y_train, 10)\n",
    "y_test = keras.utils.to_categorical(y_test, 10)\n",
    "# END CODE HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ptTRSDo5nJyZ"
   },
   "outputs": [],
   "source": [
    "# Reshape to proper images with 1 color channel according to backend scheme\n",
    "# img_rows, img_cols = train_images.shape[1], train_images.shape[2]\n",
    "# train_images = train_images.reshape(...)\n",
    "# START CODE HERE\n",
    "\n",
    "x_train = x_train.reshape((60000,784))\n",
    "x_test = x_test.reshape((10000,784))\n",
    "                         \n",
    "# END CODE HERE\n",
    "\n",
    "# Cast pixels from uint8 to float32\n",
    "#train_images = train_images.astype('float32')\n",
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "\n",
    "# Now let us normalize the images so that they have zero mean and standard deviation\n",
    "# Hint: are real testing data statistics known at training time ?\n",
    "# START CODE HERE\n",
    "x_train /= 255.0\n",
    "x_test /= 255.0\n",
    "# END CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "lnKYaP-KVoOs"
   },
   "source": [
    "## Defining the neural network architecture (i.e., the network model)\n",
    "\n",
    "Look at this [cheatsheet](https://s3.amazonaws.com/assets.datacamp.com/blog_assets/Keras_Cheat_Sheet_Python.pdf) for some basic information on how to use numpy.\n",
    "\n",
    "First, try to replicate the classifier of the first exercise. Secondly, create a fully connected network.\n",
    "For the fully connected layer, you can for example use this architecture: \n",
    "$$ (784) \\rightarrow (300) \\rightarrow (10) $$\n",
    "For this first implementation of the network, use only sigmoid activations in the hidden layer. Remember to use the right output activation function ! "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Classifier of first exercise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Pnd3q1V3nk8v"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 10)                7850      \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 10)                110       \n",
      "=================================================================\n",
      "Total params: 7,960\n",
      "Trainable params: 7,960\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# The Sequential module is a container for more complex NN elements and\n",
    "# defines a loop-less NN architecture\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, Flatten\n",
    "\n",
    "# START CODE HERE\n",
    "input_shape = 784\n",
    "output_shape = 10\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(output_shape, activation=\"sigmoid\", input_shape = (input_shape,)))\n",
    "model.add(Dense(output_shape, activation='sigmoid'))\n",
    "\n",
    "model.summary()\n",
    "\n",
    "# END CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Classifier fully connected with the architecture\n",
    "$$ (784) \\rightarrow (300) \\rightarrow (10) $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_3 (Dense)              (None, 784)               615440    \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 300)               235500    \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 10)                3010      \n",
      "=================================================================\n",
      "Total params: 853,950\n",
      "Trainable params: 853,950\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# The Sequential module is a container for more complex NN elements and\n",
    "# defines a loop-less NN architecture\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, Flatten\n",
    "\n",
    "# START CODE HERE\n",
    "input_shape = 784\n",
    "output_shape = 10\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(input_shape, activation=\"sigmoid\", input_shape = (input_shape,)))\n",
    "model.add(Dense(300, activation='sigmoid'))\n",
    "model.add(Dense(output_shape, activation='sigmoid'))\n",
    "\n",
    "model.summary()\n",
    "\n",
    "# END CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "7g2PNEiwWBLw"
   },
   "source": [
    "Instantiate a SGD optimizer with a tentative learning rate of $\\\\eta = 10^{-2}$ and, using the appropriate loss function (which is called, in keras, ```'categorical_crossentropy'```) and compile the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "SijGZGKjV9J2",
    "outputId": "ae6c8734-e7ec-46e7-f019-6711f5980c67"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_3 (Dense)              (None, 784)               615440    \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 300)               235500    \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 10)                3010      \n",
      "=================================================================\n",
      "Total params: 853,950\n",
      "Trainable params: 853,950\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# The optimizers module provides a number of optimization algorithms for updating\n",
    "# a netwok parameters accoridng to the computed error gradints\n",
    "from keras import optimizers\n",
    "\n",
    "# START CODE HERE\n",
    "sgd = optimizers.SGD(lr=0.01, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "model.compile(optimizer=sgd,\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "# END CODE HERE\n",
    "# We can now have a look at the defined model topology\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "u-WqMtSAWTRp"
   },
   "source": [
    "## Training the network\n",
    "\n",
    "Train the model for 10 epochs using the ```.fit()``` method, validating the model at each epoch and keeping track of the training history for later plotting. Make sure you enable ```.fit()``` verbose mode in order to visualize the training.\n",
    "\n",
    "In order to accelerate training, use the ```batch_size``` option of ```.fit()```, which will process a batch of examples at the same time, and make one update for all of them, averaged over the gradients for each training example of the batch. You can begin with a small size, and experiment with a larger size later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "gTHrbb7uFYWz"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "60000/60000 [==============================] - 11s 183us/step - loss: 0.9171 - accuracy: 0.7192 - val_loss: 0.3602 - val_accuracy: 0.8942\n",
      "Epoch 2/10\n",
      "60000/60000 [==============================] - 19s 308us/step - loss: 0.3449 - accuracy: 0.8993 - val_loss: 0.2979 - val_accuracy: 0.9140\n",
      "Epoch 3/10\n",
      "60000/60000 [==============================] - 18s 306us/step - loss: 0.3052 - accuracy: 0.9098 - val_loss: 0.2785 - val_accuracy: 0.9201\n",
      "Epoch 4/10\n",
      "60000/60000 [==============================] - 17s 278us/step - loss: 0.2795 - accuracy: 0.9180 - val_loss: 0.2734 - val_accuracy: 0.9203\n",
      "Epoch 5/10\n",
      "60000/60000 [==============================] - 17s 288us/step - loss: 0.2579 - accuracy: 0.9242 - val_loss: 0.2369 - val_accuracy: 0.9302\n",
      "Epoch 6/10\n",
      "60000/60000 [==============================] - 10s 160us/step - loss: 0.2380 - accuracy: 0.9308 - val_loss: 0.2224 - val_accuracy: 0.9360\n",
      "Epoch 7/10\n",
      "60000/60000 [==============================] - 9s 156us/step - loss: 0.2199 - accuracy: 0.9352 - val_loss: 0.2129 - val_accuracy: 0.9402\n",
      "Epoch 8/10\n",
      "60000/60000 [==============================] - 9s 156us/step - loss: 0.2020 - accuracy: 0.9404 - val_loss: 0.1961 - val_accuracy: 0.9404\n",
      "Epoch 9/10\n",
      "60000/60000 [==============================] - 9s 152us/step - loss: 0.1871 - accuracy: 0.9451 - val_loss: 0.1842 - val_accuracy: 0.9456\n",
      "Epoch 10/10\n",
      "60000/60000 [==============================] - 8s 141us/step - loss: 0.1742 - accuracy: 0.9485 - val_loss: 0.1648 - val_accuracy: 0.9504\n"
     ]
    }
   ],
   "source": [
    "# This is where the actual training-testing happens\n",
    "# Number of epochs we want to train\n",
    "epochs = 10\n",
    "\n",
    "# START CODE HERE\n",
    "history = model.fit(x_train,y_train,\n",
    "          batch_size=32,\n",
    "          epochs=epochs,\n",
    "          verbose=1,\n",
    "          validation_data = (x_test,y_test))\n",
    "# END CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ODUc5Bq_dMEq"
   },
   "source": [
    "## Visualizing the network performance\n",
    "\n",
    "Visualize the training history using the ```pyplot``` package:\n",
    "- In one graph, plot the train and vaidation loss functions,\n",
    "- In another graph, the train and validation accuracy.\n",
    "By comparing the training the testing curves, what can we conclude about the quality of the training ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "QdJrRbyariEw"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['val_loss', 'val_accuracy', 'loss', 'accuracy'])\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'acc'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-dba089aeae55>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m# START CODE HERE\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfigsize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m15\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m8\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'acc'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'val_acc'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtitle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'model accuracy'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'acc'"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1080x576 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "# We now want to plot the train and validation loss functions and accuracy curves\n",
    "print(history.history.keys())\n",
    "\n",
    "# summarize history for loss\n",
    "# START CODE HERE\n",
    "plt.figure(figsize=(15,8))\n",
    "plt.plot(history.history['acc'])\n",
    "plt.plot(history.history['val_acc'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()\n",
    "# END CODE HERE\n",
    "\n",
    "\n",
    "# summarize history for accuracy\n",
    "# START CODE HERE\n",
    "plt.figure(figsize=(15,8))\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()\n",
    "# END CODE HERE\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We finish with a validation accuracy of 0.9468, this is so well model to predict new values."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Nr4TdWoEoDzi"
   },
   "source": [
    "## Experiments\n",
    "\n",
    "Note down the performance of the larger network in terms of training and validation accuracy as a reference (save the loss/accuracy graphs of the network).\n",
    "\n",
    "Then, experiment as follow and compare performance with the reference scenario:\n",
    "\n",
    "*  Experiment increasing the size of the batch and compare the performance with reference.\n",
    "*  Experiment replacing the sigmoid activations with Relus and note what happens.\n",
    "*  Experiment with a larger architecture, for example: \n",
    "$$ (784) \\rightarrow (300) \\rightarrow (128) \\rightarrow (84) \\rightarrow (10) $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experiment increasing the size of the batch to 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1\n",
    "\n",
    "epochs = 10\n",
    "\n",
    "input_shape = 784\n",
    "output_shape = 10\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(input_shape, activation=\"sigmoid\", input_shape = (input_shape,)))\n",
    "model.add(Dense(300, activation='sigmoid'))\n",
    "model.add(Dense(output_shape, activation='sigmoid'))\n",
    "\n",
    "model.summary()\n",
    "\n",
    "sgd = optimizers.SGD(lr=0.01, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "model.compile(optimizer=sgd,\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "history = model.fit(x_train,y_train,\n",
    "          batch_size=128,\n",
    "          epochs=epochs,\n",
    "          verbose=1,\n",
    "          validation_data = (x_test,y_test))\n",
    "\n",
    "print(history.history.keys())\n",
    "\n",
    "# summarize history for loss\n",
    "plt.figure(figsize=(15,8))\n",
    "plt.plot(history.history['acc'])\n",
    "plt.plot(history.history['val_acc'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()\n",
    "\n",
    "# summarize history for accuracy\n",
    "plt.figure(figsize=(15,8))\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>This model have a validation accuracy decreased in around 0.02</b>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experiment replacing the sigmoid activations with Relus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2\n",
    "\n",
    "epochs = 10\n",
    "\n",
    "input_shape = 784\n",
    "output_shape = 10\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(input_shape, activation=\"relu\", input_shape = (input_shape,)))\n",
    "model.add(Dense(300, activation='relu'))\n",
    "model.add(Dense(output_shape, activation='relu'))\n",
    "\n",
    "model.summary()\n",
    "\n",
    "sgd = optimizers.SGD(lr=0.01, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "model.compile(optimizer=sgd,\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "history = model.fit(x_train,y_train,\n",
    "          batch_size=32,\n",
    "          epochs=epochs,\n",
    "          verbose=1,\n",
    "          validation_data = (x_test,y_test))\n",
    "\n",
    "print(history.history.keys())\n",
    "\n",
    "# summarize history for loss\n",
    "plt.figure(figsize=(15,8))\n",
    "plt.plot(history.history['acc'])\n",
    "plt.plot(history.history['val_acc'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()\n",
    "\n",
    "# summarize history for accuracy\n",
    "plt.figure(figsize=(15,8))\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>We obtained so bad results when we switch all functions activations to relus.</b>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experiment with a larger architecture\n",
    "$$ (784) \\rightarrow (300) \\rightarrow (128) \\rightarrow (84) \\rightarrow (10) $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3\n",
    "\n",
    "epochs = 10\n",
    "\n",
    "input_shape = 784\n",
    "output_shape = 10\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(input_shape, activation=\"sigmoid\", input_shape = (input_shape,)))\n",
    "model.add(Dense(300, activation='sigmoid'))\n",
    "model.add(Dense(128, activation='sigmoid'))\n",
    "model.add(Dense(84, activation='sigmoid'))\n",
    "model.add(Dense(output_shape, activation='softmax'))\n",
    "\n",
    "model.summary()\n",
    "\n",
    "sgd = optimizers.SGD(lr=0.01, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "adadelta = optimizers.Adadelta(lr=1.0, rho=0.95)\n",
    "model.compile(optimizer=adadelta,\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "history = model.fit(x_train,y_train,\n",
    "          batch_size=32,\n",
    "          epochs=epochs,\n",
    "          verbose=1,\n",
    "          validation_data = (x_test,y_test))\n",
    "\n",
    "print(history.history.keys())\n",
    "\n",
    "# summarize history for loss\n",
    "plt.figure(figsize=(15,8))\n",
    "plt.plot(history.history['acc'])\n",
    "plt.plot(history.history['val_acc'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()\n",
    "\n",
    "# summarize history for accuracy\n",
    "plt.figure(figsize=(15,8))\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>This is our best result, the model obtained a validation accuracy of 0.9707 which is so well.</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "TP4_1_empty.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
