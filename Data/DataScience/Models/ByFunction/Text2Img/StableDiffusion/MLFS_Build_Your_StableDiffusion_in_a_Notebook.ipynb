{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rNwRr-frtUWF"
      },
      "source": [
        "## Machine Learning from Scratch: Stable Diffusion\n",
        "Binxu Wang\n",
        "\n",
        "Nov.2022\n",
        "\n",
        "This notebook walk you through how to build your Unet architecture from scratch! All the network components are defined in a single notebook. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "habUA6HPrWzo"
      },
      "outputs": [],
      "source": [
        "# !pip install einops"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "271Up9v8q2pp"
      },
      "outputs": [],
      "source": [
        "import math\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from einops import rearrange\n",
        "from collections import OrderedDict\n",
        "from easydict import EasyDict as edict"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xiDr0zU3tAbR"
      },
      "source": [
        "## Define our Unet Architecture"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x_n42yfVsDKz"
      },
      "source": [
        "### Build Our ResBlock"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "RSB8S64Jrb9D"
      },
      "outputs": [],
      "source": [
        "# backbone, Residual Block (Checked)\n",
        "class ResBlock(nn.Module):\n",
        "    def __init__(self, in_channel, time_emb_dim, out_channel=None, ):\n",
        "        super().__init__()\n",
        "        if out_channel is None:\n",
        "            out_channel = in_channel\n",
        "        self.norm1 = nn.GroupNorm(32, in_channel, eps=1e-05, affine=True)\n",
        "        self.conv1 = nn.Conv2d(in_channel, out_channel, kernel_size=3, stride=1, padding=1)\n",
        "        self.time_emb_proj = nn.Linear(in_features=time_emb_dim, out_features=out_channel, bias=True)\n",
        "        self.norm2 = nn.GroupNorm(32, out_channel, eps=1e-05, affine=True)\n",
        "        self.dropout = nn.Dropout(p=0.0, inplace=False)\n",
        "        self.conv2 = nn.Conv2d(out_channel, out_channel, kernel_size=3, stride=1, padding=1)\n",
        "        self.nonlinearity = nn.SiLU()\n",
        "        if in_channel == out_channel:\n",
        "            self.conv_shortcut = nn.Identity()\n",
        "        else:\n",
        "            self.conv_shortcut = nn.Conv2d(in_channel, out_channel, kernel_size=1, stride=1)\n",
        "\n",
        "    def forward(self, x, t_emb, cond=None):\n",
        "        # Input conv\n",
        "        h = self.norm1(x)\n",
        "        h = self.nonlinearity(h)\n",
        "        h = self.conv1(h)\n",
        "        # Time modulation\n",
        "        if t_emb is not None:\n",
        "            t_hidden = self.time_emb_proj(self.nonlinearity(t_emb))\n",
        "            h = h + t_hidden[:, :, None, None]\n",
        "        # Output conv\n",
        "        h = self.norm2(h)\n",
        "        h = self.nonlinearity(h)\n",
        "        h = self.dropout(h)\n",
        "        h = self.conv2(h)\n",
        "        # Skip connection\n",
        "        return h + self.conv_shortcut(x)\n",
        "\n",
        "\n",
        "# UpSampling (Checked)\n",
        "class UpSample(nn.Module):\n",
        "    def __init__(self, channel, scale_factor=2, mode='nearest'):\n",
        "        super(UpSample, self).__init__()\n",
        "        self.scale_factor = scale_factor\n",
        "        self.mode = mode\n",
        "        self.conv = nn.Conv2d(channel, channel, kernel_size=3, stride=1, padding=1, )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = F.interpolate(x, scale_factor=self.scale_factor, mode=self.mode)\n",
        "        return self.conv(x)\n",
        "\n",
        "\n",
        "# DownSampling (Checked)\n",
        "class DownSample(nn.Module):\n",
        "    def __init__(self, channel, ):\n",
        "        super(DownSample, self).__init__()\n",
        "        self.conv = nn.Conv2d(channel, channel, kernel_size=3, stride=2, padding=1, )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.conv(x)  # F.interpolate(x, scale_factor=1/self.scale_factor, mode=self.mode)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9zxxh3AFsGMl"
      },
      "source": [
        "### Build Our Attention / Transformer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "PhTnJAFmsM6C"
      },
      "outputs": [],
      "source": [
        "# Self and Cross Attention mechanism (Checked)\n",
        "class CrossAttention(nn.Module):\n",
        "    \"\"\"General implementation of Cross & Self Attention multi-head\n",
        "    \"\"\"\n",
        "    def __init__(self, embed_dim, hidden_dim, context_dim=None, num_heads=8, ):\n",
        "        super(CrossAttention, self).__init__()\n",
        "        self.hidden_dim = hidden_dim\n",
        "        self.context_dim = context_dim\n",
        "        self.embed_dim = embed_dim\n",
        "        self.num_heads = num_heads\n",
        "        self.head_dim = embed_dim // num_heads\n",
        "        self.to_q = nn.Linear(hidden_dim, embed_dim, bias=False)\n",
        "        if context_dim is None:\n",
        "            # Self Attention\n",
        "            self.to_k = nn.Linear(hidden_dim, embed_dim, bias=False)\n",
        "            self.to_v = nn.Linear(hidden_dim, embed_dim, bias=False)\n",
        "            self.self_attn = True\n",
        "        else:\n",
        "            # Cross Attention\n",
        "            self.to_k = nn.Linear(context_dim, embed_dim, bias=False)\n",
        "            self.to_v = nn.Linear(context_dim, embed_dim, bias=False)\n",
        "            self.self_attn = False\n",
        "        self.to_out = nn.Sequential(\n",
        "            nn.Linear(embed_dim, hidden_dim, bias=True)\n",
        "        )  # this could be omitted\n",
        "\n",
        "    def forward(self, tokens, context=None):\n",
        "        Q = self.to_q(tokens)\n",
        "        K = self.to_k(tokens) if self.self_attn else self.to_k(context)\n",
        "        V = self.to_v(tokens) if self.self_attn else self.to_v(context)\n",
        "        # print(Q.shape, K.shape, V.shape)\n",
        "        # transform heads onto batch dimension\n",
        "        Q = rearrange(Q, 'B T (H D) -> (B H) T D', H=self.num_heads, D=self.head_dim)\n",
        "        K = rearrange(K, 'B T (H D) -> (B H) T D', H=self.num_heads, D=self.head_dim)\n",
        "        V = rearrange(V, 'B T (H D) -> (B H) T D', H=self.num_heads, D=self.head_dim)\n",
        "        # print(Q.shape, K.shape, V.shape)\n",
        "        scoremats = torch.einsum(\"BTD,BSD->BTS\", Q, K)\n",
        "        attnmats = F.softmax(scoremats / math.sqrt(self.head_dim), dim=-1)\n",
        "        # print(scoremats.shape, attnmats.shape, )\n",
        "        ctx_vecs = torch.einsum(\"BTS,BSD->BTD\", attnmats, V)\n",
        "        # split the heads transform back to hidden.\n",
        "        ctx_vecs = rearrange(ctx_vecs, '(B H) T D -> B T (H D)', H=self.num_heads, D=self.head_dim)\n",
        "        # TODO: note this `to_out` is also a linear layer, could be in principle merged into the to_value layer.\n",
        "        return self.to_out(ctx_vecs)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "bJtqJDnFro1J"
      },
      "outputs": [],
      "source": [
        "# Transformer layers\n",
        "class TransformerBlock(nn.Module):\n",
        "    def __init__(self, hidden_dim, context_dim, num_heads=8):\n",
        "        super(TransformerBlock, self).__init__()\n",
        "        self.attn1 = CrossAttention(hidden_dim, hidden_dim, num_heads=num_heads)  # self attention\n",
        "        self.attn2 = CrossAttention(hidden_dim, hidden_dim, context_dim, num_heads=num_heads)  # cross attention\n",
        "\n",
        "        self.norm1 = nn.LayerNorm(hidden_dim)\n",
        "        self.norm2 = nn.LayerNorm(hidden_dim)\n",
        "        self.norm3 = nn.LayerNorm(hidden_dim)\n",
        "        # to be compatible with Diffuser, could simplify.\n",
        "        self.ff = FeedForward_GEGLU(hidden_dim, )\n",
        "        # A more common version used in transformers. \n",
        "        # self.ff = nn.Sequential(\n",
        "        #     nn.Linear(hidden_dim, 3 * hidden_dim),\n",
        "        #     nn.GELU(),\n",
        "        #     nn.Linear(3 * hidden_dim, hidden_dim)\n",
        "        # )\n",
        "\n",
        "    def forward(self, x, context=None):\n",
        "        x = self.attn1(self.norm1(x)) + x\n",
        "        x = self.attn2(self.norm2(x), context=context) + x\n",
        "        x = self.ff(self.norm3(x)) + x\n",
        "        return x\n",
        "\n",
        "\n",
        "class GEGLU_proj(nn.Module):\n",
        "    def __init__(self, in_dim, out_dim):\n",
        "        super(GEGLU_proj, self).__init__()\n",
        "        self.proj = nn.Linear(in_dim, 2 * out_dim)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.proj(x)\n",
        "        x, gates = x.chunk(2, dim=-1)\n",
        "        return x * F.gelu(gates)\n",
        "\n",
        "\n",
        "class FeedForward_GEGLU(nn.Module):\n",
        "    # https://github.com/huggingface/diffusers/blob/95414bd6bf9bb34a312a7c55f10ba9b379f33890/src/diffusers/models/attention.py#L339\n",
        "    # A variant of the gated linear unit activation function from https://arxiv.org/abs/2002.05202.\n",
        "    def __init__(self, hidden_dim, mult=4):\n",
        "        super(FeedForward_GEGLU, self).__init__()\n",
        "        self.net = nn.Sequential(\n",
        "            GEGLU_proj(hidden_dim, mult * hidden_dim),\n",
        "            nn.Dropout(0.0),\n",
        "            nn.Linear(mult * hidden_dim, hidden_dim)\n",
        "        )  # to be compatible with Diffuser, could simplify.\n",
        "\n",
        "    def forward(self, x, ):\n",
        "        return self.net(x)\n",
        "\n",
        "\n",
        "class SpatialTransformer(nn.Module):\n",
        "    def __init__(self, hidden_dim, context_dim, num_heads=8):\n",
        "        super(SpatialTransformer, self).__init__()\n",
        "        self.norm = nn.GroupNorm(32, hidden_dim, eps=1e-6, affine=True)\n",
        "        self.proj_in = nn.Conv2d(hidden_dim, hidden_dim, kernel_size=1, stride=1, padding=0)\n",
        "        # self.transformer = TransformerBlock(hidden_dim, context_dim, num_heads=8)\n",
        "        self.transformer_blocks = nn.Sequential(\n",
        "            TransformerBlock(hidden_dim, context_dim, num_heads=8)\n",
        "        )  # to be compatible with Diffuser, could simplify.\n",
        "        self.proj_out = nn.Conv2d(hidden_dim, hidden_dim, kernel_size=1, stride=1, padding=0)\n",
        "\n",
        "    def forward(self, x, cond=None):\n",
        "        b, c, h, w = x.shape\n",
        "        x_in = x\n",
        "        # context = rearrange(context, \"b c T -> b T c\")\n",
        "        x = self.proj_in(self.norm(x))\n",
        "        x = rearrange(x, \"b c h w->b (h w) c\")\n",
        "        x = self.transformer_blocks[0](x, cond)\n",
        "        x = rearrange(x, 'b (h w) c -> b c h w', h=h, w=w)\n",
        "        return self.proj_out(x) + x_in\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ufUpHrD-viBQ"
      },
      "source": [
        "### Container of ResBlock and Spatial Transformers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "sWQ4TR6krtpb"
      },
      "outputs": [],
      "source": [
        "# Modified Container. Modify the nn.Sequential to time modulated Sequential\n",
        "class TimeModulatedSequential(nn.Sequential):\n",
        "    \"\"\" Modify the nn.Sequential to time modulated Sequential \"\"\"\n",
        "    def forward(self, x, t_emb, cond=None):\n",
        "        for module in self:\n",
        "            if isinstance(module, TimeModulatedSequential):\n",
        "                x = module(x, t_emb, cond)\n",
        "            elif isinstance(module, ResBlock):\n",
        "                # For certain layers, add the time modulation.\n",
        "                x = module(x, t_emb)\n",
        "            elif isinstance(module, SpatialTransformer):\n",
        "                # For certain layers, add the class conditioning.\n",
        "                x = module(x, cond=cond)\n",
        "            else:\n",
        "                x = module(x)\n",
        "\n",
        "        return x\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5JecMwdLr3H7"
      },
      "source": [
        "### Putting it Together into UNet!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "G0-WVZ_ir1-x"
      },
      "outputs": [],
      "source": [
        "class UNet_SD(nn.Module):\n",
        "\n",
        "    def __init__(self, in_channels=4,\n",
        "                 base_channels=320,\n",
        "                 time_emb_dim=1280,\n",
        "                 context_dim=768,\n",
        "                 multipliers=(1, 2, 4, 4),\n",
        "                 attn_levels=(0, 1, 2),\n",
        "                 nResAttn_block=2,\n",
        "                 cat_unet=True):\n",
        "        super().__init__()\n",
        "        self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "        self.in_channels = in_channels\n",
        "        self.out_channels = in_channels\n",
        "        base_channels = base_channels\n",
        "        time_emb_dim = time_emb_dim\n",
        "        context_dim = context_dim\n",
        "        multipliers = multipliers\n",
        "        nlevel = len(multipliers)\n",
        "        self.base_channels = base_channels\n",
        "        # attn_levels = [0, 1, 2]\n",
        "        level_channels = [base_channels * mult for mult in multipliers]\n",
        "        # Transform time into embedding\n",
        "        self.time_embedding = nn.Sequential(OrderedDict({\n",
        "            \"linear_1\": nn.Linear(base_channels, time_emb_dim, bias=True),\n",
        "            \"act\": nn.SiLU(),\n",
        "            \"linear_2\": nn.Linear(time_emb_dim, time_emb_dim, bias=True),\n",
        "        })\n",
        "        )  # 2 layer MLP\n",
        "        self.conv_in = nn.Conv2d(self.in_channels, base_channels, 3, stride=1, padding=1)\n",
        "\n",
        "        # Tensor Downsample blocks\n",
        "        nResAttn_block = nResAttn_block\n",
        "        self.down_blocks = TimeModulatedSequential()  # nn.ModuleList()\n",
        "        self.down_blocks_channels = [base_channels]\n",
        "        cur_chan = base_channels\n",
        "        for i in range(nlevel):\n",
        "            for j in range(nResAttn_block):\n",
        "                res_attn_sandwich = TimeModulatedSequential()\n",
        "                # input_chan of first ResBlock is different from the rest.\n",
        "                res_attn_sandwich.append(ResBlock(in_channel=cur_chan, time_emb_dim=time_emb_dim, out_channel=level_channels[i]))\n",
        "                if i in attn_levels:\n",
        "                    # add attention except for the last level\n",
        "                    res_attn_sandwich.append(SpatialTransformer(level_channels[i], context_dim=context_dim))\n",
        "                cur_chan = level_channels[i]\n",
        "                self.down_blocks.append(res_attn_sandwich)\n",
        "                self.down_blocks_channels.append(cur_chan)\n",
        "            # res_attn_sandwich.append(DownSample(level_channels[i]))\n",
        "            if not i == nlevel - 1:\n",
        "                self.down_blocks.append(TimeModulatedSequential(DownSample(level_channels[i])))\n",
        "                self.down_blocks_channels.append(cur_chan)\n",
        "\n",
        "        self.mid_block = TimeModulatedSequential(\n",
        "            ResBlock(cur_chan, time_emb_dim),\n",
        "            SpatialTransformer(cur_chan, context_dim=context_dim),\n",
        "            ResBlock(cur_chan, time_emb_dim),\n",
        "        )\n",
        "\n",
        "        # Tensor Upsample blocks\n",
        "        self.up_blocks = nn.ModuleList() # TimeModulatedSequential()  #\n",
        "        for i in reversed(range(nlevel)):\n",
        "            for j in range(nResAttn_block + 1):\n",
        "                res_attn_sandwich = TimeModulatedSequential()\n",
        "                res_attn_sandwich.append(ResBlock(in_channel=cur_chan + self.down_blocks_channels.pop(),\n",
        "                                                  time_emb_dim=time_emb_dim, out_channel=level_channels[i]))\n",
        "                if i in attn_levels:\n",
        "                    res_attn_sandwich.append(SpatialTransformer(level_channels[i], context_dim=context_dim))\n",
        "                cur_chan = level_channels[i]\n",
        "                if j == nResAttn_block and i != 0:\n",
        "                    res_attn_sandwich.append(UpSample(level_channels[i]))\n",
        "                self.up_blocks.append(res_attn_sandwich)\n",
        "        # Read out from tensor to latent space\n",
        "        self.output = nn.Sequential(\n",
        "            nn.GroupNorm(32, base_channels, ),\n",
        "            nn.SiLU(),\n",
        "            nn.Conv2d(base_channels, self.out_channels, 3, padding=1),\n",
        "        )\n",
        "        self.to(self.device)\n",
        "      \n",
        "    def time_proj(self, time_steps, max_period: int = 10000):\n",
        "        if time_steps.ndim == 0:\n",
        "            time_steps = time_steps.unsqueeze(0)\n",
        "        half = self.base_channels // 2\n",
        "        frequencies = torch.exp(- math.log(max_period)\n",
        "                                * torch.arange(start=0, end=half, dtype=torch.float32) / half\n",
        "                                ).to(device=time_steps.device)\n",
        "        angles = time_steps[:, None].float() * frequencies[None, :]\n",
        "        return torch.cat([torch.cos(angles), torch.sin(angles)], dim=-1)\n",
        "\n",
        "    def forward(self, x, time_steps, cond=None, encoder_hidden_states=None, output_dict=True):\n",
        "        if cond is None and encoder_hidden_states is not None:\n",
        "            cond = encoder_hidden_states\n",
        "        t_emb = self.time_proj(time_steps)\n",
        "        t_emb = self.time_embedding(t_emb)\n",
        "        x = self.conv_in(x)\n",
        "        down_x_cache = [x]\n",
        "        for module in self.down_blocks:\n",
        "            x = module(x, t_emb, cond)\n",
        "            down_x_cache.append(x)\n",
        "        x = self.mid_block(x, t_emb, cond)\n",
        "        for module in self.up_blocks:\n",
        "            x = module(torch.cat((x, down_x_cache.pop()), dim=1), t_emb, cond)\n",
        "        x = self.output(x)\n",
        "        if output_dict:\n",
        "            return edict(sample=x)\n",
        "        else:\n",
        "            return x\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EH7n8CYIt3yt"
      },
      "source": [
        "## Unit test the components with the UNet implementation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ahIZYziluEHS"
      },
      "source": [
        "### Check ResNet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "99467f4415ef4e61b80e5dc9a0dd5e0e",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.sv…"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "from huggingface_hub import notebook_login\n",
        "\n",
        "notebook_login()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-01-05 19:24:07.136473: I tensorflow/core/util/util.cc:169] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n"
          ]
        },
        {
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'transformers.modeling_outputs'",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[9], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mtorch\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtorch\u001b[39;00m \u001b[39mimport\u001b[39;00m autocast\n\u001b[0;32m----> 3\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mdiffusers\u001b[39;00m \u001b[39mimport\u001b[39;00m StableDiffusionPipeline\n\u001b[1;32m      4\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mmatplotlib\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpyplot\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mplt\u001b[39;00m\n",
            "File \u001b[0;32m~/anaconda3/envs/tf_1_12_gpu/lib/python3.8/site-packages/diffusers/__init__.py:27\u001b[0m\n\u001b[1;32m     25\u001b[0m     \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mutils\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mdummy_pt_objects\u001b[39;00m \u001b[39mimport\u001b[39;00m \u001b[39m*\u001b[39m  \u001b[39m# noqa F403\u001b[39;00m\n\u001b[1;32m     26\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m---> 27\u001b[0m     \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mmodeling_utils\u001b[39;00m \u001b[39mimport\u001b[39;00m ModelMixin\n\u001b[1;32m     28\u001b[0m     \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mmodels\u001b[39;00m \u001b[39mimport\u001b[39;00m (\n\u001b[1;32m     29\u001b[0m         AutoencoderKL,\n\u001b[1;32m     30\u001b[0m         PriorTransformer,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     35\u001b[0m         VQModel,\n\u001b[1;32m     36\u001b[0m     )\n\u001b[1;32m     37\u001b[0m     \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39moptimization\u001b[39;00m \u001b[39mimport\u001b[39;00m (\n\u001b[1;32m     38\u001b[0m         get_constant_schedule,\n\u001b[1;32m     39\u001b[0m         get_constant_schedule_with_warmup,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     44\u001b[0m         get_scheduler,\n\u001b[1;32m     45\u001b[0m     )\n",
            "File \u001b[0;32m~/anaconda3/envs/tf_1_12_gpu/lib/python3.8/site-packages/diffusers/modeling_utils.py:52\u001b[0m\n\u001b[1;32m     48\u001b[0m     _LOW_CPU_MEM_USAGE_DEFAULT \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n\u001b[1;32m     51\u001b[0m \u001b[39mif\u001b[39;00m is_accelerate_available():\n\u001b[0;32m---> 52\u001b[0m     \u001b[39mimport\u001b[39;00m \u001b[39maccelerate\u001b[39;00m\n\u001b[1;32m     53\u001b[0m     \u001b[39mfrom\u001b[39;00m \u001b[39maccelerate\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mutils\u001b[39;00m \u001b[39mimport\u001b[39;00m set_module_tensor_to_device\n\u001b[1;32m     54\u001b[0m     \u001b[39mfrom\u001b[39;00m \u001b[39maccelerate\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mutils\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mversions\u001b[39;00m \u001b[39mimport\u001b[39;00m is_torch_version\n",
            "File \u001b[0;32m~/anaconda3/envs/tf_1_12_gpu/lib/python3.8/site-packages/accelerate/__init__.py:7\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39m# flake8: noqa\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[39m# There's no way to ignore \"F401 '...' imported but unused\" warnings in this\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[39m# module, but to preserve other warnings. So, don't check this module at all.\u001b[39;00m\n\u001b[1;32m      5\u001b[0m __version__ \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m0.15.0\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m----> 7\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39maccelerator\u001b[39;00m \u001b[39mimport\u001b[39;00m Accelerator\n\u001b[1;32m      8\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mbig_modeling\u001b[39;00m \u001b[39mimport\u001b[39;00m cpu_offload, disk_offload, dispatch_model, init_empty_weights, load_checkpoint_and_dispatch\n\u001b[1;32m      9\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mlaunchers\u001b[39;00m \u001b[39mimport\u001b[39;00m debug_launcher, notebook_launcher\n",
            "File \u001b[0;32m~/anaconda3/envs/tf_1_12_gpu/lib/python3.8/site-packages/accelerate/accelerator.py:27\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtyping\u001b[39;00m \u001b[39mimport\u001b[39;00m List, Optional, Union\n\u001b[1;32m     25\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mtorch\u001b[39;00m\n\u001b[0;32m---> 27\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mcheckpointing\u001b[39;00m \u001b[39mimport\u001b[39;00m load_accelerator_state, load_custom_state, save_accelerator_state, save_custom_state\n\u001b[1;32m     28\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mdata_loader\u001b[39;00m \u001b[39mimport\u001b[39;00m DataLoaderDispatcher, prepare_data_loader\n\u001b[1;32m     29\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mlogging\u001b[39;00m \u001b[39mimport\u001b[39;00m get_logger\n",
            "File \u001b[0;32m~/anaconda3/envs/tf_1_12_gpu/lib/python3.8/site-packages/accelerate/checkpointing.py:24\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mtorch\u001b[39;00m\n\u001b[1;32m     22\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtorch\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcuda\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mamp\u001b[39;00m \u001b[39mimport\u001b[39;00m GradScaler\n\u001b[0;32m---> 24\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mutils\u001b[39;00m \u001b[39mimport\u001b[39;00m (\n\u001b[1;32m     25\u001b[0m     MODEL_NAME,\n\u001b[1;32m     26\u001b[0m     OPTIMIZER_NAME,\n\u001b[1;32m     27\u001b[0m     RNG_STATE_NAME,\n\u001b[1;32m     28\u001b[0m     SCALER_NAME,\n\u001b[1;32m     29\u001b[0m     SCHEDULER_NAME,\n\u001b[1;32m     30\u001b[0m     get_pretty_name,\n\u001b[1;32m     31\u001b[0m     is_tpu_available,\n\u001b[1;32m     32\u001b[0m     save,\n\u001b[1;32m     33\u001b[0m )\n\u001b[1;32m     36\u001b[0m \u001b[39mif\u001b[39;00m is_tpu_available(check_device\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m):\n\u001b[1;32m     37\u001b[0m     \u001b[39mimport\u001b[39;00m \u001b[39mtorch_xla\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcore\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mxla_model\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mxm\u001b[39;00m\n",
            "File \u001b[0;32m~/anaconda3/envs/tf_1_12_gpu/lib/python3.8/site-packages/accelerate/utils/__init__.py:103\u001b[0m\n\u001b[1;32m     93\u001b[0m     \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mdeepspeed\u001b[39;00m \u001b[39mimport\u001b[39;00m (\n\u001b[1;32m     94\u001b[0m         DeepSpeedEngineWrapper,\n\u001b[1;32m     95\u001b[0m         DeepSpeedOptimizerWrapper,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     99\u001b[0m         HfDeepSpeedConfig,\n\u001b[1;32m    100\u001b[0m     )\n\u001b[1;32m    102\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mlaunch\u001b[39;00m \u001b[39mimport\u001b[39;00m PrepareForLaunch, _filter_args, get_launch_prefix\n\u001b[0;32m--> 103\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mmegatron_lm\u001b[39;00m \u001b[39mimport\u001b[39;00m (\n\u001b[1;32m    104\u001b[0m     AbstractTrainStep,\n\u001b[1;32m    105\u001b[0m     BertTrainStep,\n\u001b[1;32m    106\u001b[0m     GPTTrainStep,\n\u001b[1;32m    107\u001b[0m     MegatronEngine,\n\u001b[1;32m    108\u001b[0m     MegatronLMDummyDataLoader,\n\u001b[1;32m    109\u001b[0m     MegatronLMDummyScheduler,\n\u001b[1;32m    110\u001b[0m     MegatronLMOptimizerWrapper,\n\u001b[1;32m    111\u001b[0m     MegatronLMSchedulerWrapper,\n\u001b[1;32m    112\u001b[0m     T5TrainStep,\n\u001b[1;32m    113\u001b[0m     avg_losses_across_data_parallel_group,\n\u001b[1;32m    114\u001b[0m     gather_across_data_parallel_groups,\n\u001b[1;32m    115\u001b[0m )\n\u001b[1;32m    116\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mmegatron_lm\u001b[39;00m \u001b[39mimport\u001b[39;00m initialize \u001b[39mas\u001b[39;00m megatron_lm_initialize\n\u001b[1;32m    117\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mmegatron_lm\u001b[39;00m \u001b[39mimport\u001b[39;00m prepare_data_loader \u001b[39mas\u001b[39;00m megatron_lm_prepare_data_loader\n",
            "File \u001b[0;32m~/anaconda3/envs/tf_1_12_gpu/lib/python3.8/site-packages/accelerate/utils/megatron_lm.py:32\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39moperations\u001b[39;00m \u001b[39mimport\u001b[39;00m recursively_apply, send_to_device\n\u001b[1;32m     31\u001b[0m \u001b[39mif\u001b[39;00m is_transformers_available():\n\u001b[0;32m---> 32\u001b[0m     \u001b[39mfrom\u001b[39;00m \u001b[39mtransformers\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mmodeling_outputs\u001b[39;00m \u001b[39mimport\u001b[39;00m (\n\u001b[1;32m     33\u001b[0m         CausalLMOutputWithCrossAttentions,\n\u001b[1;32m     34\u001b[0m         Seq2SeqLMOutput,\n\u001b[1;32m     35\u001b[0m         SequenceClassifierOutput,\n\u001b[1;32m     36\u001b[0m     )\n\u001b[1;32m     39\u001b[0m \u001b[39mif\u001b[39;00m is_megatron_lm_available():\n\u001b[1;32m     40\u001b[0m     \u001b[39mfrom\u001b[39;00m \u001b[39mmegatron\u001b[39;00m \u001b[39mimport\u001b[39;00m (\n\u001b[1;32m     41\u001b[0m         get_args,\n\u001b[1;32m     42\u001b[0m         get_num_microbatches,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     48\u001b[0m         print_rank_last,\n\u001b[1;32m     49\u001b[0m     )\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'transformers.modeling_outputs'"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "from torch import autocast\n",
        "from diffusers import StableDiffusionPipeline\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "application/json": {
              "ascii": false,
              "bar_format": null,
              "colour": null,
              "elapsed": 0.00648045539855957,
              "initial": 0,
              "n": 0,
              "ncols": null,
              "nrows": null,
              "postfix": null,
              "prefix": "Fetching 16 files",
              "rate": null,
              "total": 16,
              "unit": "it",
              "unit_divisor": 1000,
              "unit_scale": false
            },
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "78b4abb5a56646cea69a12b994e82f74",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Fetching 16 files:   0%|          | 0/16 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "pipe = StableDiffusionPipeline.from_pretrained(\n",
        "    \"CompVis/stable-diffusion-v1-4\",\n",
        "    use_auth_token=False\n",
        ").to(\"cuda\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wpj8MbYtuCGv"
      },
      "outputs": [],
      "source": [
        "def test_ResBlock(pipe):\n",
        "    tmp_blk = ResBlock(320, 1280).cuda()\n",
        "    std_blk = pipe.unet.down_blocks[0].resnets[0]\n",
        "    SD = std_blk.state_dict()\n",
        "    tmp_blk.load_state_dict(SD)\n",
        "    lat_tmp = torch.randn(3, 320, 32, 32)\n",
        "    temb = torch.randn(3, 1280)\n",
        "    with torch.no_grad():\n",
        "        out = pipe.unet.down_blocks[0].resnets[0](lat_tmp.cuda(),temb.cuda())\n",
        "        out2 = tmp_blk(lat_tmp.cuda(), temb.cuda())\n",
        "\n",
        "    assert torch.allclose(out2, out)\n",
        "\n",
        "test_ResBlock(pipe)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ODTE3D0quStC"
      },
      "outputs": [],
      "source": [
        "def test_downsampler(pipe):\n",
        "    tmpdsp = DownSample(320).cuda()\n",
        "    stddsp = pipe.unet.down_blocks[0].downsamplers[0]\n",
        "    SD = stddsp.state_dict()\n",
        "    tmpdsp.load_state_dict(SD)\n",
        "    lat_tmp = torch.randn(3, 320, 32, 32)\n",
        "    with torch.no_grad():\n",
        "        out = stddsp(lat_tmp.cuda())\n",
        "        out2 = tmpdsp(lat_tmp.cuda())\n",
        "\n",
        "    assert torch.allclose(out2, out)\n",
        "\n",
        "def test_upsampler(pipe):\n",
        "    tmpusp = UpSample(1280).cuda()\n",
        "    stdusp = pipe.unet.up_blocks[1].upsamplers[0]\n",
        "    SD = stdusp.state_dict()\n",
        "    tmpusp.load_state_dict(SD)\n",
        "    lat_tmp = torch.randn(3, 1280, 32, 32)\n",
        "    with torch.no_grad():\n",
        "        out = stdusp(lat_tmp.cuda())\n",
        "        out2 = tmpusp(lat_tmp.cuda())\n",
        "\n",
        "    assert torch.allclose(out2, out)\n",
        "\n",
        "test_downsampler(pipe)\n",
        "test_upsampler(pipe)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9ECH9vN_umz9"
      },
      "source": [
        "### Check Attention"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mBeZ09w_uc_p"
      },
      "outputs": [],
      "source": [
        "def test_self_attention(pipe):\n",
        "    tmpSattn = CrossAttention(320, 320, context_dim=None, num_heads=8).cuda()\n",
        "    stdSattn = pipe.unet.down_blocks[0].attentions[0].transformer_blocks[0].attn1\n",
        "    tmpSattn.load_state_dict(stdSattn.state_dict())  # checked\n",
        "    with torch.no_grad():\n",
        "        lat_tmp = torch.randn(3, 32, 320)\n",
        "        out = stdSattn(lat_tmp.cuda())\n",
        "        out2 = tmpSattn(lat_tmp.cuda())\n",
        "    assert torch.allclose(out2, out)  # False\n",
        "\n",
        "#%%\n",
        "# Check Cross attention\n",
        "def test_cross_attention(pipe):\n",
        "    tmpXattn = CrossAttention(320, 320, context_dim=768, num_heads=8).cuda()\n",
        "    stdXattn = pipe.unet.down_blocks[0].attentions[0].transformer_blocks[0].attn2\n",
        "    tmpXattn.load_state_dict(stdXattn.state_dict())  # checked\n",
        "    with torch.no_grad():\n",
        "        lat_tmp = torch.randn(3, 32, 320)\n",
        "        ctx_tmp = torch.randn(3, 5, 768)\n",
        "        out = stdXattn(lat_tmp.cuda(), ctx_tmp.cuda())\n",
        "        out2 = tmpXattn(lat_tmp.cuda(), ctx_tmp.cuda())\n",
        "    assert torch.allclose(out2, out)  # False\n",
        "\n",
        "test_self_attention(pipe)\n",
        "test_cross_attention(pipe)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CLaHTKtQu72T"
      },
      "source": [
        "### Check Transformer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XN_tLHSzu62o"
      },
      "outputs": [
        {
          "ename": "TypeError",
          "evalue": "allclose(): argument 'input' (position 1) must be Tensor, not Transformer2DModelOutput",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[14], line 27\u001b[0m\n\u001b[1;32m     24\u001b[0m     \u001b[39massert\u001b[39;00m torch\u001b[39m.\u001b[39mallclose(out2, out)  \u001b[39m# False\u001b[39;00m\n\u001b[1;32m     26\u001b[0m test_TransformerBlock(pipe)\n\u001b[0;32m---> 27\u001b[0m test_SpatialTransformer(pipe)\n",
            "Cell \u001b[0;32mIn[14], line 24\u001b[0m, in \u001b[0;36mtest_SpatialTransformer\u001b[0;34m(pipe)\u001b[0m\n\u001b[1;32m     22\u001b[0m     out \u001b[39m=\u001b[39m tmpSpTfmer(lat_tmp\u001b[39m.\u001b[39mcuda(), ctx_tmp\u001b[39m.\u001b[39mcuda())\n\u001b[1;32m     23\u001b[0m     out2 \u001b[39m=\u001b[39m stdSpTfmer(lat_tmp\u001b[39m.\u001b[39mcuda(), ctx_tmp\u001b[39m.\u001b[39mcuda())\n\u001b[0;32m---> 24\u001b[0m \u001b[39massert\u001b[39;00m torch\u001b[39m.\u001b[39;49mallclose(out2, out)\n",
            "\u001b[0;31mTypeError\u001b[0m: allclose(): argument 'input' (position 1) must be Tensor, not Transformer2DModelOutput"
          ]
        }
      ],
      "source": [
        "#%% test TransformerBlock Implementation\n",
        "def test_TransformerBlock(pipe):\n",
        "    tmpTfmer = TransformerBlock(320, context_dim=768, num_heads=8).cuda()\n",
        "    stdTfmer = pipe.unet.down_blocks[0].attentions[0].transformer_blocks[0]\n",
        "    tmpTfmer.load_state_dict(stdTfmer.state_dict())  # checked\n",
        "    with torch.no_grad():\n",
        "        lat_tmp = torch.randn(3, 32, 320)\n",
        "        ctx_tmp = torch.randn(3, 5, 768)\n",
        "        out = tmpTfmer(lat_tmp.cuda(), ctx_tmp.cuda())\n",
        "        out2 = stdTfmer(lat_tmp.cuda(), ctx_tmp.cuda())\n",
        "    assert torch.allclose(out2, out)  # False\n",
        "\n",
        "\n",
        "#%% test SpatialTransformer Implementation\n",
        "def test_SpatialTransformer(pipe):\n",
        "    tmpSpTfmer = SpatialTransformer(320, context_dim=768, num_heads=8).cuda()\n",
        "    stdSpTfmer = pipe.unet.down_blocks[0].attentions[0]\n",
        "    tmpSpTfmer.load_state_dict(stdSpTfmer.state_dict())  # checked\n",
        "    with torch.no_grad():\n",
        "        lat_tmp = torch.randn(3, 320, 8, 8)\n",
        "        ctx_tmp = torch.randn(3, 5, 768)\n",
        "        out = tmpSpTfmer(lat_tmp.cuda(), ctx_tmp.cuda())\n",
        "        out2 = stdSpTfmer(lat_tmp.cuda(), ctx_tmp.cuda())\n",
        "    assert torch.allclose(out2, out)  # False\n",
        "\n",
        "test_TransformerBlock(pipe)\n",
        "test_SpatialTransformer(pipe)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UDRviSqDsQ5r"
      },
      "source": [
        "## Load Weights into our UNet! "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ir7QUBnGs1ye"
      },
      "outputs": [],
      "source": [
        "# !pip install diffusers transformers tokenizers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EoVDMCfvs3gN"
      },
      "outputs": [],
      "source": [
        "from huggingface_hub import notebook_login\n",
        "\n",
        "notebook_login()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H3ovjx71sshL"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch import autocast\n",
        "from diffusers import StableDiffusionPipeline\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M_GZHkIosvV-"
      },
      "outputs": [],
      "source": [
        "pipe = StableDiffusionPipeline.from_pretrained(\n",
        "    \"CompVis/stable-diffusion-v1-4\",\n",
        "    use_auth_token=False\n",
        ").to(\"cuda\")\n",
        "def dummy_checker(images, **kwargs): return images, False\n",
        "pipe.safety_checker = dummy_checker"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L5Qb_jNcvWyf"
      },
      "source": [
        "### Test the Entire UNet model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "G_h_6tcQsOOI"
      },
      "outputs": [],
      "source": [
        "#@title Utils to load weights\n",
        "def load_pipe_into_our_UNet(myUNet, pipe_unet):\n",
        "    # load the pretrained weights from the pipe into our UNet.\n",
        "    # Loading input and output layers.\n",
        "    myUNet.output[0].load_state_dict(pipe_unet.conv_norm_out.state_dict())\n",
        "    myUNet.output[2].load_state_dict(pipe_unet.conv_out.state_dict())\n",
        "    myUNet.conv_in.load_state_dict(pipe_unet.conv_in.state_dict())\n",
        "    myUNet.time_embedding.load_state_dict(pipe_unet.time_embedding.state_dict())\n",
        "    #% Loading the down blocks\n",
        "    myUNet.down_blocks[0][0].load_state_dict(pipe_unet.down_blocks[0].resnets[0].state_dict())\n",
        "    myUNet.down_blocks[0][1].load_state_dict(pipe_unet.down_blocks[0].attentions[0].state_dict())\n",
        "    myUNet.down_blocks[1][0].load_state_dict(pipe_unet.down_blocks[0].resnets[1].state_dict())\n",
        "    myUNet.down_blocks[1][1].load_state_dict(pipe_unet.down_blocks[0].attentions[1].state_dict())\n",
        "    myUNet.down_blocks[2][0].load_state_dict(pipe_unet.down_blocks[0].downsamplers[0].state_dict())\n",
        "\n",
        "    myUNet.down_blocks[3][0].load_state_dict(pipe_unet.down_blocks[1].resnets[0].state_dict())\n",
        "    myUNet.down_blocks[3][1].load_state_dict(pipe_unet.down_blocks[1].attentions[0].state_dict())\n",
        "    myUNet.down_blocks[4][0].load_state_dict(pipe_unet.down_blocks[1].resnets[1].state_dict())\n",
        "    myUNet.down_blocks[4][1].load_state_dict(pipe_unet.down_blocks[1].attentions[1].state_dict())\n",
        "    myUNet.down_blocks[5][0].load_state_dict(pipe_unet.down_blocks[1].downsamplers[0].state_dict())\n",
        "\n",
        "    myUNet.down_blocks[6][0].load_state_dict(pipe_unet.down_blocks[2].resnets[0].state_dict())\n",
        "    myUNet.down_blocks[6][1].load_state_dict(pipe_unet.down_blocks[2].attentions[0].state_dict())\n",
        "    myUNet.down_blocks[7][0].load_state_dict(pipe_unet.down_blocks[2].resnets[1].state_dict())\n",
        "    myUNet.down_blocks[7][1].load_state_dict(pipe_unet.down_blocks[2].attentions[1].state_dict())\n",
        "    myUNet.down_blocks[8][0].load_state_dict(pipe_unet.down_blocks[2].downsamplers[0].state_dict())\n",
        "\n",
        "    myUNet.down_blocks[9][0].load_state_dict(pipe_unet.down_blocks[3].resnets[0].state_dict())\n",
        "    myUNet.down_blocks[10][0].load_state_dict(pipe_unet.down_blocks[3].resnets[1].state_dict())\n",
        "\n",
        "    #% Loading the middle blocks\n",
        "    myUNet.mid_block[0].load_state_dict(pipe_unet.mid_block.resnets[0].state_dict())\n",
        "    myUNet.mid_block[1].load_state_dict(pipe_unet.mid_block.attentions[0].state_dict())\n",
        "    myUNet.mid_block[2].load_state_dict(pipe_unet.mid_block.resnets[1].state_dict())\n",
        "    # % Loading the up blocks\n",
        "    # upblock 0\n",
        "    myUNet.up_blocks[0][0].load_state_dict(pipe_unet.up_blocks[0].resnets[0].state_dict())\n",
        "    myUNet.up_blocks[1][0].load_state_dict(pipe_unet.up_blocks[0].resnets[1].state_dict())\n",
        "    myUNet.up_blocks[2][0].load_state_dict(pipe_unet.up_blocks[0].resnets[2].state_dict())\n",
        "    myUNet.up_blocks[2][1].load_state_dict(pipe_unet.up_blocks[0].upsamplers[0].state_dict())\n",
        "    # % upblock 1\n",
        "    myUNet.up_blocks[3][0].load_state_dict(pipe_unet.up_blocks[1].resnets[0].state_dict())\n",
        "    myUNet.up_blocks[3][1].load_state_dict(pipe_unet.up_blocks[1].attentions[0].state_dict())\n",
        "    myUNet.up_blocks[4][0].load_state_dict(pipe_unet.up_blocks[1].resnets[1].state_dict())\n",
        "    myUNet.up_blocks[4][1].load_state_dict(pipe_unet.up_blocks[1].attentions[1].state_dict())\n",
        "    myUNet.up_blocks[5][0].load_state_dict(pipe_unet.up_blocks[1].resnets[2].state_dict())\n",
        "    myUNet.up_blocks[5][1].load_state_dict(pipe_unet.up_blocks[1].attentions[2].state_dict())\n",
        "    myUNet.up_blocks[5][2].load_state_dict(pipe_unet.up_blocks[1].upsamplers[0].state_dict())\n",
        "    # % upblock 2\n",
        "    myUNet.up_blocks[6][0].load_state_dict(pipe_unet.up_blocks[2].resnets[0].state_dict())\n",
        "    myUNet.up_blocks[6][1].load_state_dict(pipe_unet.up_blocks[2].attentions[0].state_dict())\n",
        "    myUNet.up_blocks[7][0].load_state_dict(pipe_unet.up_blocks[2].resnets[1].state_dict())\n",
        "    myUNet.up_blocks[7][1].load_state_dict(pipe_unet.up_blocks[2].attentions[1].state_dict())\n",
        "    myUNet.up_blocks[8][0].load_state_dict(pipe_unet.up_blocks[2].resnets[2].state_dict())\n",
        "    myUNet.up_blocks[8][1].load_state_dict(pipe_unet.up_blocks[2].attentions[2].state_dict())\n",
        "    myUNet.up_blocks[8][2].load_state_dict(pipe_unet.up_blocks[2].upsamplers[0].state_dict())\n",
        "    # % upblock 3\n",
        "    myUNet.up_blocks[9][0].load_state_dict(pipe_unet.up_blocks[3].resnets[0].state_dict())\n",
        "    myUNet.up_blocks[9][1].load_state_dict(pipe_unet.up_blocks[3].attentions[0].state_dict())\n",
        "    myUNet.up_blocks[10][0].load_state_dict(pipe_unet.up_blocks[3].resnets[1].state_dict())\n",
        "    myUNet.up_blocks[10][1].load_state_dict(pipe_unet.up_blocks[3].attentions[1].state_dict())\n",
        "    myUNet.up_blocks[11][0].load_state_dict(pipe_unet.up_blocks[3].resnets[2].state_dict())\n",
        "    myUNet.up_blocks[11][1].load_state_dict(pipe_unet.up_blocks[3].attentions[2].state_dict())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "voTf2vo6sm1T"
      },
      "outputs": [],
      "source": [
        "myunet = UNet_SD()\n",
        "original_unet = pipe.unet.cpu()\n",
        "load_pipe_into_our_UNet(myunet, original_unet)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BwFZstOIspxB"
      },
      "outputs": [],
      "source": [
        "pipe.unet = myunet.cuda()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V1dpo2ortQqS"
      },
      "outputs": [],
      "source": [
        "prompt = \"A ballerina riding a Harley Motorcycle, CG Art\"\n",
        "with autocast(\"cuda\"):\n",
        "    image = pipe(prompt)[\"sample\"][0]\n",
        "\n",
        "image.save(\"astronaut_rides_horse.png\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "EH7n8CYIt3yt",
        "ahIZYziluEHS",
        "9ECH9vN_umz9",
        "CLaHTKtQu72T"
      ],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "tf_1_12_gpu",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.11 (default, Aug  3 2021, 15:09:35) \n[GCC 7.5.0]"
    },
    "vscode": {
      "interpreter": {
        "hash": "573820ecbabff0910b89582aa997743d1a3f9cd0ecc1387e1cf8631a33508dc3"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
